
#Automatically generated by Colab.

#importing dependecies

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

# load the dataset to pandas dataframe
cc_data = pd.read_csv("creditcard.csv")

# printing firts 5 rows of the datset
cc_data.head()

cc_data.tail()

cc_data.info()

# checking the no. of missing values in the dataset
cc_data.isnull().sum()

# check the distribution of legit and fraud transactions
cc_data['Class'].value_counts()

"""Highly unbalanced dataset"""

#seperate data points
legit = cc_data[cc_data.Class == 0]
frauds= cc_data[cc_data.Class == 1]
print(legit.shape)
print(frauds.shape)

# statistics
legit.Amount.describe()

frauds.Amount.describe()

# compare values
cc_data.groupby('Class').mean()

"""build a sample dataset usoing undersampling that contains similar legit and fraud transaction
no.of fraud transac = 492

take random 492 legit transac and combine with 492 frauds transac
"""

legit_sample = legit.sample(n=492)

#concatenate 2 dataframes
new_dataset = pd.concat([legit_sample,frauds], axis=0)
#to stack up more columns = 1
#to stack up more rows = 0

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

#here we seperate the feature and target

#the feature data set will be used to train a seprate dataset and so with the target

#feature will contain the input data to make predictions
#y is what we are trying to predict (fraud or legit)


# split data into features and targets
#the feature data set will be used to train a seprate dataset and so with the target
#feature will contain the input data to make predictions y is what we are trying to predict (fraud or legit)

x= new_dataset.drop(columns='Class',axis=1)
y= new_dataset['Class']
print(x)

print(y)

#split data into training data and testing data
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,stratify=y,random_state=2)

print(x.shape,x_train.shape,x_test.shape)

#Model Training

#Logistic regression


scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

mod = LogisticRegression(max_iter=8000)

#trainig the logistic regression model with training data
mod.fit(x_train,y_train)

# Model Evaluation
# Accuracy Score
x_train_prediction = mod.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction,y_train)

print('Accuracy = ',training_data_accuracy)

# accuracy on test data
x_test_prediction = mod.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction,y_test)

print('Accuracy = ',test_data_accuracy)
